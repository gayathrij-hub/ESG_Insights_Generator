{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom headers (SEC requires contact info in User-Agent)\n",
    "HEADERS = {\n",
    "    'User-Agent': 'Gayathri Jayaraman (gayathrij@uchicago.edu)',\n",
    "    'Accept-Encoding': 'gzip, deflate',\n",
    "    'Host': 'data.sec.gov'\n",
    "}\n",
    "\n",
    "BASE_URL = \"https://data.sec.gov/submissions/CIK{}.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_company_filings(cik):\n",
    "    \"\"\"Fetch submissions for a company based on CIK\"\"\"\n",
    "    cik = str(cik).zfill(10)  # Ensure CIK is zero-padded\n",
    "    url = BASE_URL.format(cik) \n",
    "    response = requests.get(url, headers=HEADERS)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        print(f\"Failed to fetch data for CIK {cik}: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def extract_filings(cik_list, filing_type=\"10-K\"):\n",
    "    \"\"\"Extract specified filing type for multiple CIKs\"\"\"\n",
    "    all_filings = []\n",
    "\n",
    "    for cik in tqdm(cik_list, desc=\"Fetching SEC filings\"):\n",
    "        data = fetch_company_filings(cik)\n",
    "        if data:\n",
    "            filings = data.get('filings', {}).get('recent', {})\n",
    "            for form, accession, report_date in zip(filings.get('form', []),\n",
    "                                                    filings.get('accessionNumber', []),\n",
    "                                                    filings.get('reportDate', [])):\n",
    "                if form == filing_type:\n",
    "                    filing_url = f\"https://www.sec.gov/Archives/edgar/data/{int(cik)}/{accession.replace('-', '')}/{accession}-index.html\"\n",
    "                    all_filings.append({\n",
    "                        \"CIK\": cik,\n",
    "                        \"Form\": form,\n",
    "                        \"AccessionNumber\": accession,\n",
    "                        \"ReportDate\": report_date,\n",
    "                        \"FilingURL\": filing_url\n",
    "                    })\n",
    "\n",
    "    return pd.DataFrame(all_filings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching SEC filings: 100%|██████████| 3/3 [00:00<00:00,  6.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          CIK  Form       AccessionNumber  ReportDate  \\\n",
      "0  0000320193  10-K  0000320193-24-000123  2024-09-28   \n",
      "1  0000320193  10-K  0000320193-23-000106  2023-09-30   \n",
      "2  0000320193  10-K  0000320193-22-000108  2022-09-24   \n",
      "3  0000320193  10-K  0000320193-21-000105  2021-09-25   \n",
      "4  0000320193  10-K  0000320193-20-000096  2020-09-26   \n",
      "\n",
      "                                           FilingURL  \n",
      "0  https://www.sec.gov/Archives/edgar/data/320193...  \n",
      "1  https://www.sec.gov/Archives/edgar/data/320193...  \n",
      "2  https://www.sec.gov/Archives/edgar/data/320193...  \n",
      "3  https://www.sec.gov/Archives/edgar/data/320193...  \n",
      "4  https://www.sec.gov/Archives/edgar/data/320193...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Example CIKs (Apple, Microsoft, Amazon)\n",
    "cik_list = ['0000320193', '0000789019', '0001018724']  \n",
    "\n",
    "# Fetch 10-K filings\n",
    "filings_df = extract_filings(cik_list)\n",
    "# filings_df.to_csv(\"sec_10k_filings.csv\", index=False)\n",
    "print(filings_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to parse filing at https://www.sec.gov/Archives/edgar/data/320193/000032019324000123/0000320193-24-000123-index.html\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/processed/sample_10k_filing.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 15\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Parse a sample filing\u001b[39;00m\n\u001b[0;32m     14\u001b[0m sample_text \u001b[38;5;241m=\u001b[39m parse_filing_text(filings_df\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFilingURL\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m---> 15\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata/processed/sample_10k_filing.txt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mw\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[0;32m     16\u001b[0m     file\u001b[38;5;241m.\u001b[39mwrite(sample_text)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\IPython\\core\\interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    322\u001b[0m     )\n\u001b[1;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/processed/sample_10k_filing.txt'"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def parse_filing_text(filing_url):\n",
    "    \"\"\"Parse and return filing text from SEC filing URL\"\"\"\n",
    "    response = requests.get(filing_url, headers=HEADERS)\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        return soup.get_text(separator=' ', strip=True)\n",
    "    else:\n",
    "        print(f\"Failed to parse filing at {filing_url}\")\n",
    "        return \"\"\n",
    "\n",
    "# Parse a sample filing\n",
    "sample_text = parse_filing_text(filings_df.iloc[0]['FilingURL'])\n",
    "with open(\"data/processed/sample_10k_filing.txt\", \"w\", encoding=\"utf-8\") as file:\n",
    "    file.write(sample_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to fetch filing page: https://www.sec.gov/Archives/edgar/data/320193/000032019324000123/0000320193-24-000123-index.html\n",
      "Failed to extract 10-K filing text.\n"
     ]
    }
   ],
   "source": [
    "# Second try: extract 10k document\n",
    "def get_10k_filing_text(filing_url):\n",
    "    \"\"\"Finds the correct 10-K document link and extracts its text\"\"\"\n",
    "    response = requests.get(filing_url, headers=HEADERS)\n",
    "    \n",
    "    if response.status_code != 200:\n",
    "        print(f\"Failed to fetch filing page: {filing_url}\")\n",
    "        return \"\"\n",
    "\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    \n",
    "    # Find the 10-K document row based on \"Description\"\n",
    "    ten_k_link = None\n",
    "    for row in soup.find_all('tr'):\n",
    "        columns = row.find_all('td')\n",
    "        if len(columns) >= 2:  # Ensure the row has enough columns\n",
    "            description = columns[1].get_text(strip=True)\n",
    "            if \"10-K\" in description:  # Match the Description\n",
    "                ten_k_link = columns[2].find('a')['href']  # Extract the Document URL\n",
    "                break\n",
    "\n",
    "    if not ten_k_link:\n",
    "        print(f\"No 10-K document found in {filing_url}\")\n",
    "        return \"\"\n",
    "\n",
    "    # Construct the full URL to the 10-K document\n",
    "    base_url = \"/\".join(filing_url.split(\"/\")[:-1])  # Remove the last part of the URL\n",
    "    ten_k_url = f\"https://www.sec.gov{ten_k_link}\"\n",
    "\n",
    "    print(f\"Fetching 10-K document: {ten_k_url}\")\n",
    "\n",
    "    # Request the 10-K document\n",
    "    response = requests.get(ten_k_url, headers=HEADERS)\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Failed to fetch 10-K document: {ten_k_url}\")\n",
    "        return \"\"\n",
    "\n",
    "    # Extract and return text content\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    return soup.get_text(separator=\" \", strip=True)\n",
    "\n",
    "\n",
    "ten_k_text = get_10k_filing_text(filings_df.iloc[0]['FilingURL'])\n",
    "if ten_k_text:\n",
    "    with open(\"data/processed/sample_10k_filing.txt\", \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(ten_k_text)\n",
    "\n",
    "    print(\"10-K filing text successfully saved.\")\n",
    "else:\n",
    "    print(\"Failed to extract 10-K filing text.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
